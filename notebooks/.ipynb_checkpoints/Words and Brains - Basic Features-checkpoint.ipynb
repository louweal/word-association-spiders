{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1a2b0469-07ab-4f2e-94e3-1a9b449e1da8",
    "_uuid": "cfdc22b3b52f2804a55909c2148ac24cde25ee77"
   },
   "source": [
    "# Words and Brains - Basic Features\n",
    "\n",
    "Welcome to my WordGame project! In this first notebook, we are going to divide the people in this dataset into two neuro-classes and extract some features basic features, such as average word length, for each of these classes.\n",
    " \n",
    "Let's open up the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "_cell_guid": "deb62cff-5811-43ea-97a4-d44f939f708c",
    "_execution_state": "idle",
    "_uuid": "8a2705ef2fd85191f2a276164e99f51188fa0298",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt #plotting\n",
    "import seaborn as sns #data visualization\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"../input/wordgame\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "1744180f7bd72a3bbc40e847bae8236e293084ba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1203</td>\n",
       "      <td>jailed</td>\n",
       "      <td>imprisoned</td>\n",
       "      <td>ecig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5839</td>\n",
       "      <td>me</td>\n",
       "      <td>liverbird</td>\n",
       "      <td>wrongplanet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2962</td>\n",
       "      <td>reach</td>\n",
       "      <td>up</td>\n",
       "      <td>sas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1066</td>\n",
       "      <td>owie</td>\n",
       "      <td>band-aid</td>\n",
       "      <td>ecig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5006</td>\n",
       "      <td>water</td>\n",
       "      <td>river</td>\n",
       "      <td>wrongplanet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  author   word1       word2       source\n",
       "0   1203  jailed  imprisoned         ecig\n",
       "1   5839      me   liverbird  wrongplanet\n",
       "2   2962   reach          up          sas\n",
       "3   1066    owie    band-aid         ecig\n",
       "4   5006   water       river  wrongplanet"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pal = sns.color_palette()\n",
    "\n",
    "#df = pd.read_csv('../input/wordgame/wordgame_20170628.csv', dtype='object')\n",
    "df = pd.read_csv('../data/processed/wordgame_20170628.csv', dtype='object')\n",
    "#store words as string\n",
    "df['word1'] = df['word1'].astype('str') \n",
    "df['word2'] = df['word2'].astype('str') \n",
    "\n",
    "# convert all words to lowercase\n",
    "df['word1'] = df['word1'].map(str).apply(lambda x: x.lower())\n",
    "df['word2'] = df['word2'].map(str).apply(lambda x: x.lower())\n",
    "\n",
    "#print first rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "42bf4bf5-9d8a-4413-acc6-2bfa76c4bd79",
    "_uuid": "f6ead72763253781b7965f079561dd8ff3762dc6"
   },
   "source": [
    "Some word association are really obvious (e.g. jailed -> imprisoned), whereas as others are absolutely not (e.g. ME -> Liverbird?). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c00a326a-e368-4fca-9015-81162717f8ca",
    "_uuid": "6846713d88ae3a03adcee96d09234b684202f698"
   },
   "source": [
    "## Sources\n",
    "We have data from 10 sources. 23% of the data was purposely scraped from autism-related websites, Aspies Central and Wrong Planet. Research has shown that persons with an ASD have different brain structure and functionality compared to persons with a neuro-typical (NT) brain, which may lead to different behaviour whilst playing an online Word Association Game. Since we do not have of diagnosical data of all persons in the dataset, we will make the assumption that everyone from the Aspies Central and Wrong Planet communities have autism, and all users from other communities do not have autism. In reality approximately 10% of all people have autism, and these people will also be present on non-autism related websites, while also not everyone in a autism-related community has autism themselves (for example NT parents seeking for advise for their autistic child). Thus this assumption will be approximately 90% correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "_cell_guid": "d2517328-a677-4552-b669-c42c1275fabd",
    "_execution_state": "idle",
    "_uuid": "44de61a95a07bdbeaafd284794c0e795011f950e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NT-pairs: 259792\n",
      "Number of ASD-pairs: 74244\n"
     ]
    }
   ],
   "source": [
    "# create a source ID \n",
    "df['sourceID'] = df['source'].astype('category').cat.codes\n",
    "\n",
    "#returns False for sources 0 (AspiesCentral) and 9 (WrongPlanet) and True for others. \n",
    "def isNt(r):\n",
    "\treturn ((r.sourceID%9)>0)\n",
    "\n",
    "#group sources based on (assumed) brain-structure of their users (neural-typical versus ASD)\n",
    "df['nt'] = df.apply(isNt, axis=1)\n",
    "print(\"Number of NT-pairs: \" + str(len(df[df['nt']])))\n",
    "print(\"Number of ASD-pairs: \" + str(len(df[df['nt']==False])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words : 60862\n",
      "Mean term frequency (word1): 25.2927754057\n",
      "Median term frequency (word1): 12.033513334636964\n"
     ]
    }
   ],
   "source": [
    "#doc length normalization!?\n",
    "#.value_counts()['myword']\n",
    "\n",
    "#10 documents\n",
    "#term frequency without normalization\n",
    "df['tf10_wn'] = df.groupby(['word1','source'])['word1'].transform('count')\n",
    "\n",
    "# normalized term frequency\n",
    "N10 = df.sourceID.value_counts(sort=False).tolist()\n",
    "\n",
    "def normTF10(r):\n",
    "    return r.tf10_wn/(N10[r.sourceID]/1e5)\n",
    "\n",
    "df['tf10'] = df.apply(normTF10, axis=1)\n",
    "df.drop('tf10_wn', 1)\n",
    "\n",
    "#2 documents\n",
    "df['tf2_wn'] = df.groupby(['word1','nt'])['word1'].transform('count')\n",
    "\n",
    "# normalized term frequency\n",
    "N2 = df.nt.value_counts(sort=False).tolist()\n",
    "\n",
    "def normTF2(r):\n",
    "    return r.tf2_wn/(N2[r.nt]/1e5)\n",
    "\n",
    "df['tf2'] = df.apply(normTF2, axis=1)\n",
    "df.drop('tf2_wn', 1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Number of unique words : \" + str(len(df['word1'].unique())))\n",
    "print(\"Mean term frequency (word1): \" + str(df['tf10'].mean()))\n",
    "print(\"Median term frequency (word1): \" + str(df['tf10'].median()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     2\n",
      "1    10\n",
      "2     5\n",
      "3     2\n",
      "4    10\n",
      "Name: df10, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#create postings lists\n",
    "aspieslist = (df['word1'][df['source']==\"aspiecentral\"]).unique().tolist()\n",
    "atu2list = (df['word1'][df['source']==\"atu2\"]).unique().tolist()\n",
    "bleeplist = (df['word1'][df['source']==\"bleeping_computer\"]).unique().tolist()\n",
    "comicslist = (df['word1'][df['source']==\"classic_comics\"]).unique().tolist()\n",
    "eciglist = (df['word1'][df['source']==\"ecig\"]).unique().tolist()\n",
    "goglist = (df['word1'][df['source']==\"gog\"]).unique().tolist()\n",
    "englishlist = (df['word1'][df['source']==\"learn_english\"]).unique().tolist()\n",
    "saslist = (df['word1'][df['source']==\"sas\"]).unique().tolist()\n",
    "fishlist = (df['word1'][df['source']==\"the_fishy\"]).unique().tolist()\n",
    "wronglist = (df['word1'][df['source']==\"wrongplanet\"]).unique().tolist()\n",
    "\n",
    "df['df10'] = (df['word1'].isin(aspieslist).astype(int) + df['word1'].isin(atu2list).astype(int) \n",
    "             + df['word1'].isin(bleeplist).astype(int) + df['word1'].isin(comicslist).astype(int)\n",
    "             + df['word1'].isin(eciglist).astype(int) + df['word1'].isin(goglist).astype(int)\n",
    "             + df['word1'].isin(englishlist).astype(int) + df['word1'].isin(saslist).astype(int)\n",
    "             + df['word1'].isin(fishlist).astype(int) + df['word1'].isin(wronglist).astype(int))\n",
    "\n",
    "ntlist = (df['word1'][df['nt']==True]).unique().tolist()\n",
    "asdlist = (df['word1'][df['nt']==False]).unique().tolist()\n",
    "df['df2'] = (df['word1'].isin(ntlist).astype(int) + df['word1'].isin(asdlist).astype(int))\n",
    "\n",
    "print(df.df10.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pair frequency!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique pairs : 249951\n",
      "Mean pair frequency: 1.40698607336\n",
      "Median pair frequency: 1.0\n",
      "Top 20 most frequent word pairs: \n",
      "\t['me:you', 'man:woman', 'up:down', 'time:clock', 'meow:meow', 'green:grass', 'dog:cat', 'house:home', 'lost:found', 'out:in', 'down:under', 'life:death', 'book:worm', 'out:side', 'doctor:who', 'day:night', 'red:blood', 'movie:film', 'king:queen', 'love:hate']\n"
     ]
    }
   ],
   "source": [
    "#concatenate word1 and word2 separated by a special character which does not appear in the words itself\n",
    "def concat(r):\n",
    "    return r.word1 + \":\" + r.word2\n",
    "\n",
    "#normalization!!\n",
    "df['pair'] = df.apply(concat, axis=1)\n",
    "\n",
    "df['pf'] = df.groupby(['pair'])['pair'].transform('count')\n",
    "df['pf10'] = df.groupby(['pair','source'])['pair'].transform('count')\n",
    "\n",
    "print(\"Number of unique pairs : \" + str(len(df['pair'].unique())))\n",
    "\n",
    "#10s\n",
    "print(\"Mean pair frequency: \" + str(df['pf10'].mean()))\n",
    "print(\"Median pair frequency: \" + str(df['pf10'].median()))\n",
    "\n",
    "freq_pairs = df.sort_values(by=['pf'], ascending=False)['pair'].unique().tolist()\n",
    "\n",
    "print(\"Top 20 most frequent word pairs: \\n\\t\"+str(freq_pairs[0:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smoothed\n",
    "\n",
    "#although unsmoothed also provides interesting insights (all words in all 10 documents are ignored)\n",
    "# explain 10+1 and 2+3\n",
    "def tfidf10(r):\n",
    "    return (r.tf10)*(np.log(1+(10/r.df10)))\n",
    "\n",
    "#numpy log = math.log?? =?\n",
    "df['tfidf10'] = df.apply(tfidf10, axis=1)\n",
    "\n",
    "\n",
    "def tfidf2(r):\n",
    "    return (r.tf2)*(np.log(1+(2/r.df2)))\n",
    "\n",
    "#numpy log = math.log?? =?\n",
    "df['tfidf2'] = df.apply(tfidf2, axis=1)\n",
    "\n",
    "#print(df['tfidf10'].head(60))\n",
    "#print(df['tfidf2'].head(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326738    aspiecentral\n",
      "Name: source, dtype: object\n",
      "['music' 'dog' 'fish' 'cat' 'chocolate' 'man' 'game' 'water' 'house' 'time']\n",
      "319118    atu2\n",
      "Name: source, dtype: object\n",
      "['bono' 'u2' 'love' 'music' 'the edge' 'me' 'macphisto' 'green'\n",
      " \"visitors can't see pics\" 'money']\n",
      "254002    bleeping_computer\n",
      "Name: source, dtype: object\n",
      "['time' 'food' 'head' 'cake' 'music' 'pie' 'ball' 'fish' 'water' 'ship']\n",
      "307084    classic_comics\n",
      "Name: source, dtype: object\n",
      "['man' 'water' 'dog' 'house' 'bird' 'black' 'money' 'power' 'cat' 'game']\n",
      "184902    ecig\n",
      "Name: source, dtype: object\n",
      "['out' 'down' 'ball' 'house' 'up' 'deter' 'happy' 'fire' 'play' 'party']\n",
      "61872    gog\n",
      "Name: source, dtype: object\n",
      "['dickory' \"ninja'd\" 'water' 'death' 'game' 'time' 'fire' 'food' 'space'\n",
      " 'music']\n",
      "63897    learn_english\n",
      "Name: source, dtype: object\n",
      "['love' 'life' 'winter' 'music' 'fun' 'food' 'mother' 'night' 'soul' 'cold']\n",
      "73938    sas\n",
      "Name: source, dtype: object\n",
      "['water' 'time' 'house' 'music' 'light' 'down' 'car' 'life' 'ball' 'money']\n",
      "329063    the_fishy\n",
      "Name: source, dtype: object\n",
      "['grimsby' 'man' 'time' 'scunthorpe' 'black' 'ball' 'mariners' 'dog' 'fish'\n",
      " 'out']\n",
      "95412    wrongplanet\n",
      "Name: source, dtype: object\n",
      "['water' 'food' 'death' 'music' 'money' 'fire' 'time' 'love' 'blood' 'dog']\n"
     ]
    }
   ],
   "source": [
    "temp = df.sort_values(by=['tfidf10'], ascending=False)\n",
    "for i in range(0,10):\n",
    "    tslice = temp[temp['sourceID']==i]\n",
    "    print(tslice['source'].head(1))\n",
    "    tslice = tslice['word1'].unique()\n",
    "    print(tslice[0:10])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OMG wrongplanet is sooo nerdy O_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PFIDF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gasket:seal' 'fargo:bank' 'rutgers:university' 'my word:my word'\n",
      " 'reenactment:civil war' 'standard deviation:math' 'walkie talkie:patient'\n",
      " 'galactica:pegasus' 'the old country:ireland' 'thunderstorms:lightning']\n",
      "['no line on the horizon:magnificent' 'bono:edge' \"o'connell street:dublin\"\n",
      " 'guitar hero:the edge' 'brad pitt:angelina jolie' 'bono:vox'\n",
      " \"the claw:edge's spaceship\" \"bono:o'connell street\" 'bono:glasses'\n",
      " 'dublin:ireland']\n",
      "['epidermis:skin' 'bleeping:sound' 'concourse:airport' 'zorba:ouzo'\n",
      " 'basketbtw:basketbtw' 'ivories:elephant' 'solver:detective' 'sass:afrass'\n",
      " 'heals:wounds' 'litigation:court']\n",
      "['nathaniel:hawthorne' 'jerry lewis:dean martin' 'irving:forbush'\n",
      " 'encounters:brief' 'wight:barrow' 'simon:says' 'scrotum:sac' 'emma:frost'\n",
      " 'peregrine:france' 'masking:tape']\n",
      "['plugged:up' 'grabbed:snatched' 'racks:shelves' 'deter:dissuade'\n",
      " 'demonstrate:exhibit' 'came:went' 'harass:bother' 'bother:pester'\n",
      " 'squeal:pig' 'jubilant:happy']\n",
      "['kombat:mortal' 'dollie:tuna' 'pussy:cat' 'glimmer:despair'\n",
      " 'quaffing:hickoring' 'sycophant:crawl' 'avian:flu' 'gog:bear'\n",
      " 'blowsy:dickory' 'copycat:killer']\n",
      "['landownership:property' 'sing along:karaoke'\n",
      " 'eye sight:short-sightedness' 'fish and chips - london:london eye'\n",
      " 'vivtory:what' 'motherday:respect'\n",
      " 'silver lining playbook:mysterious girl' 'elbrus:russia'\n",
      " 'honor killing:tomato bullfight' 'lynne:social work']\n",
      "['abilify:medication' 'meow:meow' 'audio:video' 'sedan:coupe'\n",
      " 'social anxiety:disorder' 'sas:anxiety' 'autumnal:colors' 'upside:down'\n",
      " 'habits:routine' 'besotted:infatuated']\n",
      "['test 1:test 2' 'test 2:test 3' 'grimsby:town' 'grimsby:docks'\n",
      " 'grimsby:great' 'docks:fish' 'mariners:rest' 'scunthorpe:dump'\n",
      " 'haystacks:giant' 'beano:dandy']\n",
      "['sails:wind' \"asperger's:syndrome\" 'fauna:flora'\n",
      " 'superboyian:supergirlian' 'armegeddon:apocalypse' 'overused:worn'\n",
      " 'pot of gold:rainbow' 'high voltage:electricity' 'routemaster:london'\n",
      " 'bobbies:pins']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "(\"'Series' object has no attribute 'pf2'\", 'occurred at index 0')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-f242d347bcf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#numpy log = math.log?? =?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pfidf2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpfidf2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpfidf2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[1;32m   3970\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3971\u001b[0m                         \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3972\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3973\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3974\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_apply_standard\u001b[0;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[1;32m   4062\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4063\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4064\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4065\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4066\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-139-f242d347bcf2>\u001b[0m in \u001b[0;36mpfidf2\u001b[0;34m(r)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpfidf2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#numpy log = math.log?? =?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2358\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m             raise AttributeError(\"'%s' object has no attribute '%s'\" %\n\u001b[0;32m-> 2360\u001b[0;31m                                  (type(self).__name__, name))\n\u001b[0m\u001b[1;32m   2361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: (\"'Series' object has no attribute 'pf2'\", 'occurred at index 0')"
     ]
    }
   ],
   "source": [
    "def pfidf10(r):\n",
    "    return (r.pf10)*(np.log(10/r.df10))\n",
    "\n",
    "#numpy log = math.log?? =?\n",
    "df['pfidf10'] = df.apply(pfidf10, axis=1)\n",
    "\n",
    "temp = df.sort_values(by=['pfidf10'], ascending=False)\n",
    "for i in range(0,10):\n",
    "    tslice = temp[temp['sourceID']==i]\n",
    "    tslice = tslice['pair'].unique()\n",
    "    print(tslice[0:10])\n",
    "    \n",
    "def pfidf2(r):\n",
    "    return (r.pf2)*(np.log(10/r.df2))\n",
    "\n",
    "#numpy log = math.log?? =?\n",
    "df['pfidf2'] = df.apply(pfidf2, axis=1)\n",
    "\n",
    "def pfidf2(r):\n",
    "    return (r.pf2)*(np.log(10/r.df2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean tfidf NT words: 13.5895529004\n",
      "Mean tfidf ASD words: 13.1986599858\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAt0AAAFECAYAAAD7toLkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8d1417fb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## plot word length histogram\n",
    "nt = df[df['nt']].tfidf2\n",
    "asd = df[df['nt']==False].tfidf2\n",
    "\n",
    "print(\"Mean tfidf NT words: \"+str(nt.mean()))\n",
    "print(\"Mean tfidf ASD words: \"+str(asd.mean()))\n",
    "\n",
    "w1 = np.ones_like(nt)/len(nt)\n",
    "w2 = np.ones_like(asd)/len(asd)\n",
    "\n",
    "bins = np.arange(-50,500,5)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "for i in reversed(range(0,2)):\n",
    "    s = df[df['nt']==i]\n",
    "    tfidf = s.tfidf2\n",
    "    #print(s.head())\n",
    "    plt.hist(tfidf, bins=bins, alpha=0.5, label=str(s.iloc[0]['nt']), weights=(np.ones_like(tfidf)/len(tfidf)))  \n",
    "\n",
    "for i in range(0,10,3):\n",
    "    s = df[df['sourceID']==i]\n",
    "    tfidf = s.tfidf10\n",
    "    #plt.hist(tfidf, bins=bins, alpha=0.3, label=s.iloc[0]['source'], weights=(np.ones_like(tfidf)/len(tfidf)))  \n",
    "\n",
    "\n",
    "#plt.hist(asd, bins=bins,alpha=0.5, label=\"ASD\", weights=w2)\n",
    "plt.yscale('log')\n",
    "plt.title('Log-histogram of tfidf')\n",
    "#plt.xlabel('tfidf')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper right')\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-5,160])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "buhbuh :(\n",
    "\n",
    "to do make a nice plot:\n",
    "\n",
    "https://juliasilge.com/blog/term-frequency-tf-idf/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "45e5e50d-fbaf-4ef3-915f-23edfcb21245",
    "_uuid": "2034dc81210570dde4db6f03ad40a6076109acc6"
   },
   "source": [
    "## Word length\n",
    "We are now ready to extract our first feature, which will be the word length. I do not expect any differences between NT'ers and ASD'ers, although I'm curious to what is the average length of English words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4fc5224c-8f48-466e-96ea-f46056edc686",
    "_execution_state": "idle",
    "_uuid": "8c4eba005db805cc4aede690485bfebc502ed4be"
   },
   "outputs": [],
   "source": [
    "df['len1'] = df['word1'].apply(lambda x:len(x))\n",
    "df['len2'] = df['word2'].apply(lambda x:len(x))\n",
    "print(\"Longest word: \" +str(df['len1'].max()))\n",
    "\n",
    "## plot word length histogram\n",
    "nt = df[df['nt']].len1\n",
    "asd = df[df['nt']==False].len1\n",
    "\n",
    "w1 = np.ones_like(nt)/len(nt)\n",
    "w2 = np.ones_like(asd)/len(asd)\n",
    "\n",
    "bins = np.arange(1,30)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.hist(nt, bins=bins, alpha=0.5, label=\"NT\", weights=w1)\n",
    "plt.hist(asd, bins=bins,alpha=0.5, label=\"ASD\", weights=w2)\n",
    "plt.title('Histogram of word lengths')\n",
    "plt.xlabel('Word length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper right')\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([1,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6e7aa25a-8968-452e-95ec-c8dd5b649554",
    "_uuid": "c7571019d430e717d37d537f5c099126dc874670"
   },
   "source": [
    "A post contains on average 7 characters. Most words are between 3 and 15 characters long. The longest word (although it is probably a sentence) is 200 characters long. Interestingly, both NT'ers and ASD'ers use words with exactly 7 characters with similar frequency although **ASD'ers tend to use words shorter than 7 characters less frequently and longer words slightly more frequently.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "77322615-4a1c-4e95-93ff-d08c9fe356c1",
    "_uuid": "0b30752a00294889b98cac9660ea3a81ba97cec0"
   },
   "source": [
    "## Word length difference\n",
    "We can also look at the difference between the word lenght of word1 and word2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3ef3d468-fcd5-4386-911a-9439b7924b1c",
    "_execution_state": "idle",
    "_uuid": "47df7e10281ffc6a2678dec626a0331c7b1b8b1e"
   },
   "outputs": [],
   "source": [
    "df['d_len'] = np.abs(df.len1 - df.len2)\n",
    "\n",
    "## plot word length histogram\n",
    "nt = df[df['nt']].d_len\n",
    "asd = df[df['nt']==False].d_len\n",
    "\n",
    "w1 = np.ones_like(nt)/len(nt)\n",
    "w2 = np.ones_like(asd)/len(asd)\n",
    "\n",
    "bins = np.arange(0,20)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.hist(nt, bins=bins, alpha=0.5, label=\"NT\", weights=w1)\n",
    "plt.hist(asd, bins=bins,alpha=0.5, label=\"ASD\", weights=w2)\n",
    "plt.title('Histogram of word lengths')\n",
    "plt.xlabel('Word length difference')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper right')\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0,15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e37d3532-58ee-4f67-b395-9895681ce43c",
    "_uuid": "152e003cafc9af95992e1c8a4dcb3a761613d3d7"
   },
   "source": [
    "Consistent with word length.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "28711ea0-a5c6-4e32-94d4-915e0c723e38",
    "_execution_state": "idle",
    "_uuid": "6580bfa5384dac4ed89447cf9246f3e6f26cbb8d"
   },
   "outputs": [],
   "source": [
    "df['d_len'] = np.abs(df.len1 - df.len2)\n",
    "\n",
    "## plot word length histogram\n",
    "nt = df[df['nt']].d_len\n",
    "asd = df[df['nt']==False].d_len\n",
    "\n",
    "w1 = np.ones_like(nt)/len(nt)\n",
    "w2 = np.ones_like(asd)/len(asd)\n",
    "\n",
    "bins = np.arange(0,20)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.hist(nt, bins=bins, alpha=0.5, label=\"NT\", weights=w1)\n",
    "plt.hist(asd, bins=bins,alpha=0.5, label=\"ASD\", weights=w2)\n",
    "plt.title('Histogram of pairwise word lengths')\n",
    "plt.xlabel('Word length difference')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper right')\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0,15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3dc9a206-2c21-4533-818c-62f2b02da78e",
    "_uuid": "dbea05d449c4b0ba08c9e73821834365d62f7da5"
   },
   "source": [
    "Often difference is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1cc2897c-355a-4a15-8272-c76614310002",
    "_uuid": "a52fed6368b964e861c6093a58fa1226bdcfa205"
   },
   "source": [
    "## User activity\n",
    "Another highly important aspect is the number and distribution of users, because ultimately we want to develop a generalizable model and not a model that models the the difference between user A and user B. Fortunately, we have a very large dataset, which makes the distribution of users a little less important. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "af7d5679-c7e3-4d89-b490-38664064ab44",
    "_execution_state": "idle",
    "_uuid": "dba8e3992d109b08b7189c93c6d56e89a0792024"
   },
   "outputs": [],
   "source": [
    "#\n",
    "print(\"Post count of most active user: \" + str(df['author'].value_counts().max()))\n",
    "print(\"Total number of users: \" + str(len(df.groupby(['author']))))\n",
    "\n",
    "nt = df[df['nt']]\n",
    "asd = df[df['nt']==False]\n",
    "nt = nt['author'].value_counts()\n",
    "asd = asd['author'].value_counts()\n",
    "\n",
    "print(\"\\tNumber of NT'ers: \" + str(len(nt)))\n",
    "print(\"\\tNumber of ASD'ers: \" + str(len(asd)))\n",
    "\n",
    "bins = np.arange(1,11800,100)\n",
    "w1 = np.ones_like(nt)/len(nt)\n",
    "w2 = np.ones_like(asd)/len(asd)\n",
    "\n",
    "#Plot\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.hist(nt, bins=bins, alpha=0.5, label=\"NT\", weights=w1)\n",
    "plt.hist(asd, bins=bins, alpha=0.5, label=\"ASD\", weights=w2)\n",
    "plt.yscale('log')\n",
    "plt.title('Log-Histogram of posts per author')\n",
    "plt.xlabel('Number of posts')\n",
    "plt.ylabel('Weighted frequency')\n",
    "plt.legend(loc='upper right')\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([1,11800])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "aa8c1f07-5fa8-4874-ae53-0d5282088590",
    "_uuid": "2d89f6b61f723835f330fa5fcc917571426e9db0"
   },
   "source": [
    "Fortunately, almost 100% of all users in both datasets have 100 or less posts. However, there are are also 3 users in the NT set who have more than 7000 posts each, one of these users even has 11053 posts, accounting for 5% of the whole NT dataset. I think he is bit obsessed with the word game.. It might be better randomly drop most of their posts from the dataset, but for now I will leave them in. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9d3cdf34-2fc9-481c-b450-2992c5f53ff2",
    "_uuid": "0408260e129bb698075a4f95fc1d3a66e13dff67"
   },
   "source": [
    "## Frequent words\n",
    "So far we know that we have more 300000 posts from more than 6000 users, but what are the most frequently occurring words? Will these words be very meaningful or just random?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "69332918-f097-4b1a-9c70-6013a25964f9",
    "_execution_state": "idle",
    "_uuid": "f3d9b21e497fc67245cc0aca6241208d4597354b"
   },
   "outputs": [],
   "source": [
    "# convert all words to lowercase\n",
    "#df['word1'] = df['word1'].map(str).apply(lambda x: x.lower())\n",
    "#df['word2'] = df['word2'].map(str).apply(lambda x: x.lower())\n",
    "\n",
    "# split NT and ASD data\n",
    "nt = df[df['nt']]\n",
    "asd = df[df['nt']==False]\n",
    "\n",
    "#word count\n",
    "print(\"NT'ers most frequent words:\\n\" + str(nt['word2'].value_counts().head(10)))\n",
    "print(\"ASD'ers most frequent words:\\n\" + str(asd['word2'].value_counts().head(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d3793149-9043-42f8-a92f-11d96c725c3a",
    "_uuid": "9e7300f71c4b82ed838ab98f500b2fdd208933c3"
   },
   "source": [
    "The most frequent words are definitely meaningful and **NT'ers and ASD'ers seem to use the same words most frequently.** Both groups even agree that *water* is (by far) the most important word of all and that *music* is the third most important word. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "aa8e7cb1-afc6-4338-8959-de59a3a6b10c",
    "_uuid": "0271351da38569c00e22882437f92298e194e1bf"
   },
   "source": [
    "## Levenshtein Distance\n",
    "We can expect that the pairs word1-word2 contain the most the most information about the human mind. For example, when someone says *rice* you might say *food* whereas I might say *mice* (because rice sounds like mice). Which of these types of word associations can be considered to be more typically autistic?\n",
    "\n",
    "To determine this, we will use the **Levensthein Distance** (also called edit distance), which measures the similarity of two words by counting the minimum number of character *edits* (insertion, deletion or substitution) required to change one word into the other. In our example rice->food will has edit distance 4, whereas rice->mice has edit distance 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9b1f1840-d114-4418-922e-eff06e40b872",
    "_execution_state": "idle",
    "_uuid": "e65a1d1a8e02ff8d100c0d45330f8d479a3f52d9"
   },
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "\n",
    "def levenshtein(r):\n",
    "\treturn Levenshtein.distance(r.word1, r.word2)\n",
    "\n",
    "#calculate levenstein distance on each row and add to dataframe\n",
    "df['edit'] = df.apply(levenshtein, axis=1)\n",
    "\n",
    "#print mean edit distance\n",
    "print(\"Mean edit distance: \"+ str(df['edit'].mean()))\n",
    "\n",
    "#split data into NT and ASD set\n",
    "nt = df[(df['nt'] == True)]\n",
    "asd = df[(df['nt'] == False)]\n",
    "\n",
    "bins = np.arange(0,20)\n",
    "weights_nt = np.ones_like(nt['edit'])/len(nt['edit'])\n",
    "weights_asd = np.ones_like(asd['edit'])/len(asd['edit'])\n",
    "\n",
    "#Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.hist(nt['edit'], bins=bins, alpha=0.5, label=\"NT\", weights=weights_nt)\n",
    "plt.hist(asd['edit'], bins=bins, alpha=0.5, label=\"ASD\", weights=weights_asd)\n",
    "plt.title('Histogram of edit distance')\n",
    "plt.xlabel('Edit distance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper right')\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0,19])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d50726eb-434b-4e6a-9d26-9a0a77a1d7e7",
    "_uuid": "4515655175c8365598bad6d888aa45f40b3189f7"
   },
   "source": [
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1e722e5c-ef64-4e74-8577-fcd0af34f4f6",
    "_execution_state": "idle",
    "_uuid": "44f5f49e4d8f9f4d8276bfcd3834fc11683c3c54"
   },
   "outputs": [],
   "source": [
    "def norm_levenshtein(r):\n",
    "    return (r.edit/((r.len1)**2 + (r.len2)**2))\n",
    "\n",
    "#calculate levenstein distance on each row and add to dataframe\n",
    "df['n_edit'] = df.apply(norm_levenshtein, axis=1)\n",
    "\n",
    "#split data into NT and ASD set\n",
    "nt = df[(df['nt'] == True)]\n",
    "asd = df[(df['nt'] == False)]\n",
    "\n",
    "bins = np.arange(0,1,0.02)\n",
    "weights_nt = np.ones_like(nt['n_edit'])/len(nt['n_edit'])\n",
    "weights_asd = np.ones_like(asd['n_edit'])/len(asd['n_edit'])\n",
    "\n",
    "#Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.hist(nt['n_edit'], bins=bins, alpha=0.5, label=\"NT\", weights=weights_nt)\n",
    "plt.hist(asd['n_edit'], bins=bins, alpha=0.5, label=\"ASD\", weights=weights_asd)\n",
    "plt.title('Histogram of normalised levenshtein distance')\n",
    "plt.xlabel('Normalised Levenshtein distance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper right')\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0,0.25])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "81a6e918-4227-41e9-bff2-25da361b0be5",
    "_uuid": "22ce14bcc025eb02e91522973b6927d0bebee3cf"
   },
   "source": [
    "# .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "41b7930d-52d7-4b23-8d7c-745c242ffe52",
    "_execution_state": "idle",
    "_uuid": "eca55cbcbf473b8b1c28769658b49aedc7c58b06",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#set output filename\n",
    "outfile = \"../data/processed/wordgame_20170628_basicfeatures.csv\"\n",
    "\n",
    "# write rows to file\n",
    "df.to_csv(outfile, sep=',', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
