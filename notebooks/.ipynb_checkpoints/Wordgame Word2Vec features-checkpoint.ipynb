{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordgame Word2Vec features\n",
    "Welcome to the second notebook in my wordgame project. In this notebook our goal is to extract a the similarity of the word pairs based on Word2Vec. Word2Vec is a model.. \n",
    "\n",
    "a) open tail\n",
    "b) compute sim \n",
    "1) Compare sim with sim of random word pairs (shift) \n",
    "2) Plot all sim dists \n",
    "3) Plot specific. word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>source</th>\n",
       "      <th>sourceID</th>\n",
       "      <th>nt</th>\n",
       "      <th>len1</th>\n",
       "      <th>len2</th>\n",
       "      <th>d_len</th>\n",
       "      <th>edit</th>\n",
       "      <th>n_edit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1203</td>\n",
       "      <td>jailed</td>\n",
       "      <td>imprisoned</td>\n",
       "      <td>ecig</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.051471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5839</td>\n",
       "      <td>me</td>\n",
       "      <td>liverbird</td>\n",
       "      <td>wrongplanet</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.094118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2962</td>\n",
       "      <td>reach</td>\n",
       "      <td>up</td>\n",
       "      <td>sas</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.172414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1066</td>\n",
       "      <td>owie</td>\n",
       "      <td>band-aid</td>\n",
       "      <td>ecig</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.087500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5006</td>\n",
       "      <td>water</td>\n",
       "      <td>river</td>\n",
       "      <td>wrongplanet</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   author   word1       word2       source  sourceID     nt  len1  len2  \\\n",
       "0    1203  jailed  imprisoned         ecig         4   True     6    10   \n",
       "1    5839      me   liverbird  wrongplanet         9  False     2     9   \n",
       "2    2962   reach          up          sas         7   True     5     2   \n",
       "3    1066    owie    band-aid         ecig         4   True     4     8   \n",
       "4    5006   water       river  wrongplanet         9  False     5     5   \n",
       "\n",
       "   d_len  edit    n_edit  \n",
       "0      4     7  0.051471  \n",
       "1      7     8  0.094118  \n",
       "2      3     5  0.172414  \n",
       "3      4     7  0.087500  \n",
       "4      0     3  0.060000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "df = pd.read_csv('../data/processed/wordgame_20170628_basicfeatures.csv', dtype={'nt': np.bool, 'word1':str, 'word2':str})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded word embeddings\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "w2v_model = KeyedVectors.load_word2vec_format('../data/external/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "print('Loaded word embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "def inVocab(r):\n",
    "    if (r.word1 in w2v_model.vocab) & (r.word2 in w2v_model.vocab):    \n",
    "        return True\n",
    "    return False\n",
    "\n",
    "df['invoc'] = df.apply(inVocab, axis=1)\n",
    "\n",
    "#\n",
    "def calcVec(x): \n",
    "\treturn w2v_model.word_vec(x)\n",
    "\n",
    "df['wv1'] = df['word1'].apply(lambda x:calcVec(x))\n",
    "df['wv2'] = df['word2'].apply(lambda x:calcVec(x))\n",
    "\n",
    "#\n",
    "def similarity(r):\n",
    "\treturn w2v_model.similarity(r.word1, r.word2)\n",
    "\n",
    "df['sim'] = df.apply(similarity, axis=1) \n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of remaining word pairs: 272708\n",
      "Mean similariy score: 0.268906919797\n"
     ]
    }
   ],
   "source": [
    "# remove a words (pairs) that are not in vocabulary\n",
    "df = df[df['invoc']]\n",
    "print(\"Number of remaining word pairs: \" +str(len(df)))\n",
    "print(\"Mean similariy score: \" +str(df['sim'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "81% of pairs in vocabulary. sim = 0.27\n",
    "\n",
    "Now random.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "(\"name 'w2v_model' is not defined\", 'occurred at index 0')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-395e0de378ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'simr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#and.. shift back!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[1;32m   3970\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3971\u001b[0m                         \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3972\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3973\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3974\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_apply_standard\u001b[0;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[1;32m   4062\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4063\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4064\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4065\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4066\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-ccaa3593500f>\u001b[0m in \u001b[0;36msimilarity\u001b[0;34m(r)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv2\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: (\"name 'w2v_model' is not defined\", 'occurred at index 0')"
     ]
    }
   ],
   "source": [
    "#\n",
    "df['word2'] = df['word2'].shift(1)\n",
    "\n",
    "df['simr'] = df.apply(similarity, axis=1)\n",
    "#and.. shift back!\n",
    "df['word2'] = df['word2'].shift(-1)\n",
    "\n",
    "# remove a words (pairs) that are not in vocabulary\n",
    "df = df[df['simr'] <= 1.0]\n",
    "print(\"Number of remaining word pairs: \" +str(len(df)))\n",
    "print(\"Mean similariy score: \" +str(df['simr'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sim = 3.5 times lower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cats 'n dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word1_list = ['music','water']\n",
    "word2_list = ['music','water']\n",
    "tdf = df[(df['word1'].isin(word1_list)) | (df['word2'].isin(word2_list))]\n",
    "#tdf = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nt = tdf[tdf['nt']].sim\n",
    "asd = tdf[tdf['nt']==False].sim\n",
    "\n",
    "print(\"Number of NT word pairs: \" + str(len(nt)))\n",
    "print(\"\\tMean similarity: \" + str(nt.mean()))\n",
    "print(\"Number of ASD word pairs: \" + str(len(asd)))\n",
    "print(\"\\tMean similarity: \" + str(asd.mean()))\n",
    "\n",
    "#plot\n",
    "w1 = np.ones_like(nt)/len(nt)\n",
    "w2 = np.ones_like(asd)/len(asd)\n",
    "bins = np.arange(-2,2,0.05)\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.hist(nt, bins=bins, alpha=0.5, label=\"NT\", weights=w1)\n",
    "plt.hist(asd, bins=bins, alpha=0.5, label=\"ASD\", weights=w2)\n",
    "plt.title('Histogram of similarity')\n",
    "plt.xlabel('Similarity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper right')\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-0.1,0.8])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000 assocations! Still differences! I think that is good? or overfitting...? \n",
    "\n",
    "What to do?? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tdf[tdf['author']%5!=0].sim\n",
    "b = tdf[tdf['author']%5==0].sim\n",
    "\n",
    "print(\"Number of A word pairs: \" + str(len(a)))\n",
    "print(\"\\tMean similarity: \" + str(nt.mean()))\n",
    "print(\"Number of B word pairs: \" + str(len(b)))\n",
    "print(\"\\tMean similarity: \" + str(asd.mean()))\n",
    "\n",
    "#plot\n",
    "w1 = np.ones_like(a)/len(a)\n",
    "w2 = np.ones_like(b)/len(b)\n",
    "bins = np.arange(-2,2,0.05)\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.hist(a, bins=bins, alpha=0.5, label=\"A\", weights=w1)\n",
    "plt.hist(b, bins=bins, alpha=0.5, label=\"B\", weights=w2)\n",
    "plt.title('Histogram of similarity')\n",
    "plt.xlabel('Similarity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper right')\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-0.1,0.8])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "#print(tdf[tdf['nt']].head(20))\n",
    "m = 500\n",
    "\n",
    "arr1 = []\n",
    "for vec in df.wv1:\n",
    "    if(len(arr1) < m):\n",
    "        arr1.append(vec)\n",
    "c1 = []\n",
    "for b in df.nt:\n",
    "    if(len(c1) < m):\n",
    "        c1.append(b)\n",
    "        \n",
    "arr2 = []        \n",
    "for vec in df.wv2:\n",
    "    if(len(arr2) < m):\n",
    "        arr2.append(vec)        \n",
    "\n",
    "c2 = []\n",
    "for b in df.nt:\n",
    "    if(len(c2) < m):\n",
    "        c2.append(b)\n",
    "#print(arr)\n",
    "\n",
    "def setCol(boo):\n",
    "    if boo == True:\n",
    "        return 'b'\n",
    "    else:\n",
    "        return 'r'\n",
    "\n",
    "#mtx = [calcVec(\"london\"), calcVec(\"england\"), calcVec(\"paris\"), calcVec(\"france\"), calcVec(\"madrid\"), calcVec(\"spain\"), calcVec(\"brussels\"), calcVec(\"belgium\")]\n",
    "#classes = [0,1,0,1,0,1,0,1]\n",
    "#print(mtx)\n",
    "\n",
    "red_mtx1 = TSNE(random_state=42).fit_transform(arr1) \n",
    "red_mtx2 = TSNE(random_state=42).fit_transform(arr2) \n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.scatter(red_mtx1[:,0], red_mtx1[:,1], marker='^',c=c1)\n",
    "plt.scatter(red_mtx2[:,0], red_mtx2[:,1], marker='v',c=c2)\n",
    "for i in range(0,m):\n",
    "    start = [red_mtx1[i,0], red_mtx1[i,1]]\n",
    "    end = [red_mtx2[i,0], red_mtx2[i,1]]\n",
    "    colo = setCol(c1[i])\n",
    "    path = [start, end]\n",
    "    plt.plot(*zip(*path),c=colo)\n",
    "axes = plt.gca()\n",
    "#axes.set_xlim([-0.0003,0.0003])\n",
    "#axes.set_ylim([-0.0005,0.0004])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
